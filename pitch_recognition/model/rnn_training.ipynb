{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "root_dir = '../dataset/Hindustani'\n",
    "data = {\"Pitch_TimeSeries\":[], \"CTonic\":[]}\n",
    "\n",
    "for concert in os.listdir(root_dir):\n",
    "    concert_path = os.path.join(root_dir, concert)\n",
    "\n",
    "    if os.path.isdir(concert_path): \n",
    "        for raga in os.listdir(concert_path): \n",
    "            raga_path = os.path.join(concert_path, raga)\n",
    "            if os.path.isdir(raga_path): \n",
    "                pitch_file = os.path.join(raga_path, f\"{raga}.pitch.txt\")\n",
    "                ctonic_file = os.path.join(raga_path, f\"{raga}.ctonic.txt\")\n",
    "\n",
    "                with open(ctonic_file, 'r') as ctf: \n",
    "                    with open(pitch_file, 'r') as pf: \n",
    "                        pitch = pf.readlines()\n",
    "                        seg_length = 3000\n",
    "                        ctonic = ctf.read().strip() \n",
    "\n",
    "                        segments = [] \n",
    "                        curr_seg = [] \n",
    "                        ctonic_val = []\n",
    "\n",
    "                        for line in pitch: \n",
    "                            timestamp, pitch = map(float, line.split())\n",
    "                            curr_seg.append(pitch)\n",
    "                            if len(curr_seg) == seg_length: \n",
    "                                segments.append(curr_seg)\n",
    "                                ctonic_val.append(ctonic)\n",
    "                                curr_seg = []\n",
    "\n",
    "                        if curr_seg: \n",
    "                            segments.append(curr_seg)\n",
    "                            ctonic_val.append(ctonic)\n",
    "\n",
    "                data['Pitch_TimeSeries'].extend(segments) \n",
    "                data[\"CTonic\"].extend(ctonic_val)    \n",
    "\n",
    "\n",
    "with open('data.json', \"w\") as fp: \n",
    "    json.dump(data, fp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:53:26.018518Z",
     "start_time": "2024-04-10T14:53:01.406446Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "with open(\"data.json\", \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "print(len(data['Pitch_TimeSeries']))\n",
    "print(len(data['CTonic']))\n",
    "X = np.array(data['Pitch_TimeSeries'])\n",
    "y = np.array(data['CTonic'])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 22:53:04.647443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11817\n",
      "11817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/zj6fq_hs7575trs1w5lb3syr0000gn/T/ipykernel_43768/2593098369.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(data['Pitch_TimeSeries'])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:53:26.028153Z",
     "start_time": "2024-04-10T14:53:26.021458Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:53:26.035791Z",
     "start_time": "2024-04-10T14:53:26.030787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(X_train[0]), len(X_test[0]), len(y_train[0]), len(y_test[0]))\n",
    "print(X_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 3000 10 10\n",
      "(8862,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:53:27.050132Z",
     "start_time": "2024-04-10T14:53:26.037772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(4, input_shape=(3000, 1))) # hardcoded for nowww\n",
    "model.add(keras.layers.Dense(64, activation='relu')) #output layer for regression\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(100, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error')\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4)                 96        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,916\n",
      "Trainable params: 6,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 22:53:26.960521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-10 22:53:26.962348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-10 22:53:26.964073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.LSTM(64, input_shape=(3000, 1)))\n",
    "# model.add(keras.layers.LSTM(64))\n",
    "# model.add(keras.layers.Dense(64, activation='relu')) #output layer for regression\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "# model.add(keras.layers.Dense(1000, activation='softmax'))\n",
    "# optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(optimizer=optimiser,\n",
    "#                   loss='mean_squared_error')\n",
    "# model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:53:29.230684Z",
     "start_time": "2024-04-10T14:53:27.054943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train  = keras.utils.pad_sequences(X_train, maxlen=3000, dtype='float32')\n",
    "X_test = keras.utils.pad_sequences(X_test, maxlen=3000, dtype='float32')\n",
    "ytofloat = np.vectorize(lambda x: float(x))\n",
    "y_train = ytofloat(y_train)\n",
    "y_test = ytofloat(y_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:01:39.644146Z",
     "start_time": "2024-04-10T14:53:29.232739Z"
    }
   },
   "cell_type": "code",
   "source": "history = model.fit(X_train, y_train, batch_size=5, epochs=3)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 22:53:29.641679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-10 22:53:29.643661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-10 22:53:29.645883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-10 22:53:30.569103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-10 22:53:30.571072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-10 22:53:30.573634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 1367s 770ms/step - loss: 23632.0762\n",
      "Epoch 2/3\n",
      "1773/1773 [==============================] - 1357s 765ms/step - loss: 23632.0801\n",
      "Epoch 3/3\n",
      "1773/1773 [==============================] - 1366s 770ms/step - loss: 23632.1016\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Evaluation\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:03:46.064699Z",
     "start_time": "2024-04-10T16:03:30.929158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_loss)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 00:03:31.323501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-11 00:03:31.326064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-11 00:03:31.328346: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 - 15s - loss: 23600.1055 - 15s/epoch - 162ms/step\n",
      "Test loss: 23600.10546875\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
